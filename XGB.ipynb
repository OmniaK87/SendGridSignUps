{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for building an XGBoost model for the Sendgrid sign up dataset\n",
    "***\n",
    "**Jake Mitchell Scott Schubert**\n",
    "\n",
    "Initially using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#To do anything\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "#Xgboost\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#random forrest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "#One-hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_boi(col, expect_type):\n",
    "    values = df[col]\n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    values = label_encoder.fit_transform(values.astype(expect_type))\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_path = 'data/signup_train_data.csv'\n",
    "test_path = 'data/signup_test_data.csv'\n",
    "\n",
    "\n",
    "# Load the data into a DataFrame \n",
    "df = pd.read_csv(train_path, low_memory=False)\n",
    "test_df = pd.read_csv(test_path, low_memory=False)\n",
    "\n",
    "# Split into X and Y\n",
    "dfLabels = df.pop(\"label\")\n",
    "#print (df.head())\n",
    "\n",
    "#Feature engineering\n",
    "'''\n",
    "    Giving up on one-hot-encoding for now.  Not converting to \n",
    "    a friendly data format for our pandas dataFrame and I'm not \n",
    "    convinced it will assist very much and would rather invest time\n",
    "    into feature engineering specific columns\n",
    "state_ohe = one_hot_boi('state', 'str')\n",
    "aoeu = pd.DataFrame(state_ohe.T)\n",
    "df['state_ohe'] = 0\n",
    "count = 0\n",
    "for row in state_ohe:\n",
    "    aoeu = pd.DataFrame(row)\n",
    "    df['state_ohe'].append(aoeu)\n",
    "    print(aoeu)\n",
    "'''\n",
    "\n",
    "#name_notes\n",
    "'''\n",
    "df['name_notes_ohe'] = df['name_notes']\n",
    "ohe = one_hot_boi('name_notes', 'str')\n",
    "pd.options.display.max_rows = 4000\n",
    "pd.options.display.max_columns = 4000\n",
    "ohe = pd.DataFrame(ohe)\n",
    "print(ohe)\n",
    "#Pursue.  \"Invalid\" with a \"name_score\" of 0 is really likely to be bad apple\n",
    "#Want to ohe the options for name_notes....should only be like 7 of them\n",
    "\"First equals Last\"\n",
    "'''\n",
    "\n",
    "\n",
    "#Feature Engineering\n",
    "\n",
    "for dataframe in [df, test_df]:\n",
    "    \n",
    "    dataframe['employee_count_high'] = 0\n",
    "    dataframe.loc[df['employee_count']  == '1 - 500', 'employee_count_high'] = 500\n",
    "    dataframe.loc[df['employee_count']  == '501 - 1,000', 'employee_count_high'] = 1000\n",
    "    dataframe.loc[df['employee_count']  == '1,001 - 5,000', 'employee_count_high'] = 5000\n",
    "    dataframe.loc[df['employee_count']  == '5,000+', 'employee_count_high'] = 10000\n",
    "    dataframe['volume_high'] = 0\n",
    "    dataframe.loc[df['volume']  == '1 - 100,000', 'volume_high'] = 100000\n",
    "    dataframe.loc[dataframe['volume']  == '100,001 - 2,500,000', 'volume_high'] = 2500000\n",
    "    dataframe.loc[dataframe['volume']  == '2,500,001 - 10,000,000', 'volume_high'] = 10000000\n",
    "    dataframe.loc[dataframe['volume']  == '10,000,000+', 'volume_high'] = 20000000\n",
    "    dataframe.loc[dataframe['volume']  == '0 to 40k', 'volume_high'] = 40000\n",
    "    dataframe.loc[dataframe['volume']  == '40k to 100k', 'volume_high'] = 100000\n",
    "    dataframe['developer'] = 0\n",
    "    dataframe.loc[dataframe['user_persona']  == 'Developer', 'developer'] = 1\n",
    "    dataframe['ceo'] = 0\n",
    "    dataframe.loc[dataframe['user_persona']  == 'CEO', 'ceo'] = 1\n",
    "    dataframe['other'] = 0\n",
    "    dataframe.loc[dataframe['user_persona']  == 'Other', 'other'] = 1\n",
    "    dataframe['marketing'] = 0\n",
    "    dataframe.loc[dataframe['user_persona']  == 'Marketing', 'marketing'] = 1\n",
    "    dataframe['technical_support'] = 0\n",
    "    dataframe.loc[dataframe['user_persona']  == 'Technical Support', 'technical_support'] = 1\n",
    "    \n",
    "    dataframe['name_notes_inv'] = 0\n",
    "    dataframe.loc[dataframe['name_notes']  == 'Invalid', 'name_notes_inv'] = 1\n",
    "    dataframe['name_notes_firstlast'] = 0\n",
    "    dataframe.loc[dataframe['name_notes']  == 'First equals Last', 'name_notes_firstlast'] = 1\n",
    "    dataframe['name_notes_inv_firstlast'] = 0\n",
    "    dataframe.loc[dataframe['name_notes']  == 'Invalid|First equals Last', 'name_notes_inv_firstlast'] = 1\n",
    "    dataframe['name_notes_sus_firstlast'] = 0\n",
    "    dataframe.loc[dataframe['name_notes']  == 'Suspect|First equals Last', 'name_notes_sus_firstlast'] = 1\n",
    "    dataframe['name_notes_sus'] = 0\n",
    "    dataframe.loc[dataframe['name_notes']  == 'Suspect', 'name_notes_sus'] = 1\n",
    "    dataframe['name_notes_inv_sus_firstlast'] = 0\n",
    "    dataframe.loc[dataframe['name_notes']  == 'Invalid|Suspect|First equals Last', 'name_notes_inv_sus_firstlast'] = 1\n",
    "    dataframe['name_notes_inv_sus'] = 0\n",
    "    dataframe.loc[dataframe['name_notes']  == 'Invalid|Suspect', 'name_notes_inv_sus'] = 1\n",
    "    dataframe['name_notes_tagbad'] = 0\n",
    "    dataframe.loc[dataframe['name_notes']  == 'Tagged Bad', 'name_notes_tagbad'] = 1\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#Temporarily parse non numerical data\n",
    "frames_to_remove = ['zip', 'city', 'website', 'state', 'country', 'registration_ip', 'company','multifactor_country_code','created_at','lead_source','marketing_channel','volume','user_persona','initial_package','employee_count','geolocation_notes','name_notes','ip_notes','community_notes','email_notes','activity_notes','fingerprint_notes']\n",
    "df = df.drop(frames_to_remove, axis = 1)\n",
    "test_df = test_df.drop(frames_to_remove, axis = 1)\n",
    "\n",
    "#print(df.head())\n",
    "#print(df['name_notes_ohe'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost approach \n",
    "\n",
    "def xgb(seed_in, TO_TEST):\n",
    "    # split data into train and test sets\n",
    "    seed = seed_in\n",
    "    test_size = 0.7\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df, dfLabels, test_size=test_size, random_state=seed)\n",
    "\n",
    "    # fit model no training data\n",
    "    model = XGBClassifier(depth = 9, eta = 0.15, n_estimators = 120)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # make predictions for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"xgb - Seed: %i    -  Accuracy: %.2f%%\" % (seed,accuracy * 100.0))\n",
    "    \n",
    "    if TO_TEST:\n",
    "        #make predictions for train data\n",
    "        y_pred = model.predict(test_df)\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "\n",
    "        d = {'id':test_df['id'], 'label':predictions}\n",
    "        preds = pd.DataFrame(data=d)\n",
    "\n",
    "        preds.to_csv('predictions.csv', index=False)\n",
    "        return model.predict_proba(test_df)\n",
    "        \n",
    "    return model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forrest approach \n",
    "\n",
    "def rf(seed, TO_TEST):\n",
    "    seed = seed\n",
    "    df2 = df\n",
    "    df2 = df2.fillna(0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df2, dfLabels, test_size=0.7, random_state=seed)\n",
    "\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
    "                min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                min_samples_leaf=1, min_samples_split=2,\n",
    "                min_weight_fraction_leaf=0.0, n_estimators=27, n_jobs=1,\n",
    "                oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "    # Use the forest's predict method on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"RF - Seed: %i    -  Accuracy: %.2f%%\" % (seed,accuracy * 100.0))\n",
    "    \n",
    "    if TO_TEST:\n",
    "        test_df2 = test_df\n",
    "        test_df2 = test_df2.fillna(0)\n",
    "        \n",
    "        #make predictions for train data\n",
    "        y_pred2 = clf.predict(test_df2)\n",
    "        predictions = [round(value) for value in y_pred2]\n",
    "\n",
    "        d = {'id':test_df['id'], 'label':predictions}\n",
    "        preds = pd.DataFrame(data=d)\n",
    "\n",
    "        preds.to_csv('predictions.csv', index=False)\n",
    "        return clf.predict_proba(test_df2)\n",
    "    \n",
    "    return (clf.predict_proba(X_test), y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF - Seed: 1    -  Accuracy: 93.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/schubydooo/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb - Seed: 1    -  Accuracy: 96.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/schubydooo/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "def combine(seed, TO_TEST, rf_weight, xgb_weight):           \n",
    "    if TO_TEST:\n",
    "        x = rf(seed, TO_TEST)\n",
    "    else:\n",
    "        #Acquire training sample\n",
    "        (x,y_test) = rf(seed, TO_TEST)\n",
    "    rand_score = [b for a,b in x]\n",
    "    \n",
    "    xgb_score = xgb(seed, TO_TEST)\n",
    "    xgb_score = [b for a,b in xgb_score]   \n",
    "\n",
    "    predictions = []\n",
    "    for i in range(0,len(rand_score)):\n",
    "        val = rand_score[i]*rf_weight + xgb_score[i]*xgb_weight\n",
    "        predictions.append(val)\n",
    "        \n",
    "    predictions = [int(round(value)) for value in predictions]\n",
    "    \n",
    "    if TO_TEST:\n",
    "        d = {'id':test_df['id'], 'label':predictions}\n",
    "        preds = pd.DataFrame(data=d)\n",
    "        preds.to_csv('predictions.csv', index=False)\n",
    "        \n",
    "    else:\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        print(\"Combine - Seed: %i    -  Accuracy: %.2f%%\" % (seed,accuracy * 100.0))       \n",
    "    \n",
    "    \n",
    "#seed, TO_TEST, rand forest weighting, xgboost weighting\n",
    "combine(1, True, 0.3, 0.7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Equal weighting: 95.74\n",
    "0.3/0.7 - 95.98\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF - Seed: 1    -  Accuracy: 93.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/schubydooo/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb - Seed: 1    -  Accuracy: 96.07%\n",
      "SEED ------------ 1\n",
      "0.01\n",
      "0.99\n",
      "\n",
      "rf . xgb = 0.010000 . 0.990000  -  Accuracy: 96.07%\n",
      "0.02\n",
      "0.98\n",
      "\n",
      "rf . xgb = 0.020000 . 0.980000  -  Accuracy: 96.07%\n",
      "0.03\n",
      "0.97\n",
      "\n",
      "rf . xgb = 0.030000 . 0.970000  -  Accuracy: 96.06%\n",
      "0.04\n",
      "0.96\n",
      "\n",
      "rf . xgb = 0.040000 . 0.960000  -  Accuracy: 96.07%\n",
      "0.05\n",
      "0.95\n",
      "\n",
      "rf . xgb = 0.050000 . 0.950000  -  Accuracy: 96.06%\n",
      "0.06\n",
      "0.94\n",
      "\n",
      "rf . xgb = 0.060000 . 0.940000  -  Accuracy: 96.06%\n",
      "0.07\n",
      "0.9299999999999999\n",
      "\n",
      "rf . xgb = 0.070000 . 0.930000  -  Accuracy: 96.06%\n",
      "0.08\n",
      "0.92\n",
      "\n",
      "rf . xgb = 0.080000 . 0.920000  -  Accuracy: 96.05%\n",
      "0.09\n",
      "0.91\n",
      "\n",
      "rf . xgb = 0.090000 . 0.910000  -  Accuracy: 96.05%\n",
      "0.1\n",
      "0.9\n",
      "\n",
      "rf . xgb = 0.100000 . 0.900000  -  Accuracy: 96.05%\n",
      "0.11\n",
      "0.89\n",
      "\n",
      "rf . xgb = 0.110000 . 0.890000  -  Accuracy: 96.06%\n",
      "0.12\n",
      "0.88\n",
      "\n",
      "rf . xgb = 0.120000 . 0.880000  -  Accuracy: 96.06%\n",
      "0.13\n",
      "0.87\n",
      "\n",
      "rf . xgb = 0.130000 . 0.870000  -  Accuracy: 96.06%\n",
      "0.14\n",
      "0.86\n",
      "\n",
      "rf . xgb = 0.140000 . 0.860000  -  Accuracy: 96.06%\n",
      "0.15\n",
      "0.85\n",
      "\n",
      "rf . xgb = 0.150000 . 0.850000  -  Accuracy: 96.05%\n",
      "0.16\n",
      "0.84\n",
      "\n",
      "rf . xgb = 0.160000 . 0.840000  -  Accuracy: 96.04%\n",
      "0.17\n",
      "0.83\n",
      "\n",
      "rf . xgb = 0.170000 . 0.830000  -  Accuracy: 96.04%\n",
      "0.18\n",
      "0.8200000000000001\n",
      "\n",
      "rf . xgb = 0.180000 . 0.820000  -  Accuracy: 96.04%\n",
      "0.19\n",
      "0.81\n",
      "\n",
      "rf . xgb = 0.190000 . 0.810000  -  Accuracy: 96.04%\n",
      "0.2\n",
      "0.8\n",
      "\n",
      "rf . xgb = 0.200000 . 0.800000  -  Accuracy: 96.03%\n",
      "0.21\n",
      "0.79\n",
      "\n",
      "rf . xgb = 0.210000 . 0.790000  -  Accuracy: 96.03%\n",
      "0.22\n",
      "0.78\n",
      "\n",
      "rf . xgb = 0.220000 . 0.780000  -  Accuracy: 96.02%\n",
      "0.23\n",
      "0.77\n",
      "\n",
      "rf . xgb = 0.230000 . 0.770000  -  Accuracy: 96.01%\n",
      "0.24\n",
      "0.76\n",
      "\n",
      "rf . xgb = 0.240000 . 0.760000  -  Accuracy: 96.01%\n",
      "0.25\n",
      "0.75\n",
      "\n",
      "rf . xgb = 0.250000 . 0.750000  -  Accuracy: 96.00%\n",
      "0.26\n",
      "0.74\n",
      "\n",
      "rf . xgb = 0.260000 . 0.740000  -  Accuracy: 96.00%\n",
      "0.27\n",
      "0.73\n",
      "\n",
      "rf . xgb = 0.270000 . 0.730000  -  Accuracy: 96.00%\n",
      "0.28\n",
      "0.72\n",
      "\n",
      "rf . xgb = 0.280000 . 0.720000  -  Accuracy: 95.99%\n",
      "0.29\n",
      "0.71\n",
      "\n",
      "rf . xgb = 0.290000 . 0.710000  -  Accuracy: 95.99%\n",
      "0.3\n",
      "0.7\n",
      "\n",
      "rf . xgb = 0.300000 . 0.700000  -  Accuracy: 95.98%\n",
      "0.31\n",
      "0.69\n",
      "\n",
      "rf . xgb = 0.310000 . 0.690000  -  Accuracy: 95.97%\n",
      "0.32\n",
      "0.6799999999999999\n",
      "\n",
      "rf . xgb = 0.320000 . 0.680000  -  Accuracy: 95.96%\n",
      "0.33\n",
      "0.6699999999999999\n",
      "\n",
      "rf . xgb = 0.330000 . 0.670000  -  Accuracy: 95.95%\n",
      "0.34\n",
      "0.6599999999999999\n",
      "\n",
      "rf . xgb = 0.340000 . 0.660000  -  Accuracy: 95.95%\n",
      "0.35\n",
      "0.65\n",
      "\n",
      "rf . xgb = 0.350000 . 0.650000  -  Accuracy: 95.94%\n",
      "0.36\n",
      "0.64\n",
      "\n",
      "rf . xgb = 0.360000 . 0.640000  -  Accuracy: 95.93%\n",
      "0.37\n",
      "0.63\n",
      "\n",
      "rf . xgb = 0.370000 . 0.630000  -  Accuracy: 95.92%\n",
      "0.38\n",
      "0.62\n",
      "\n",
      "rf . xgb = 0.380000 . 0.620000  -  Accuracy: 95.91%\n",
      "0.39\n",
      "0.61\n",
      "\n",
      "rf . xgb = 0.390000 . 0.610000  -  Accuracy: 95.91%\n",
      "0.4\n",
      "0.6\n",
      "\n",
      "rf . xgb = 0.400000 . 0.600000  -  Accuracy: 95.89%\n",
      "0.41\n",
      "0.5900000000000001\n",
      "\n",
      "rf . xgb = 0.410000 . 0.590000  -  Accuracy: 95.88%\n",
      "0.42\n",
      "0.5800000000000001\n",
      "\n",
      "rf . xgb = 0.420000 . 0.580000  -  Accuracy: 95.88%\n",
      "0.43\n",
      "0.5700000000000001\n",
      "\n",
      "rf . xgb = 0.430000 . 0.570000  -  Accuracy: 95.86%\n",
      "0.44\n",
      "0.56\n",
      "\n",
      "rf . xgb = 0.440000 . 0.560000  -  Accuracy: 95.85%\n",
      "0.45\n",
      "0.55\n",
      "\n",
      "rf . xgb = 0.450000 . 0.550000  -  Accuracy: 95.83%\n",
      "0.46\n",
      "0.54\n",
      "\n",
      "rf . xgb = 0.460000 . 0.540000  -  Accuracy: 95.83%\n",
      "0.47\n",
      "0.53\n",
      "\n",
      "rf . xgb = 0.470000 . 0.530000  -  Accuracy: 95.81%\n",
      "0.48\n",
      "0.52\n",
      "\n",
      "rf . xgb = 0.480000 . 0.520000  -  Accuracy: 95.80%\n",
      "0.49\n",
      "0.51\n",
      "\n",
      "rf . xgb = 0.490000 . 0.510000  -  Accuracy: 95.78%\n",
      "0.5\n",
      "0.5\n",
      "\n",
      "rf . xgb = 0.500000 . 0.500000  -  Accuracy: 95.74%\n",
      "0.51\n",
      "0.49\n",
      "\n",
      "rf . xgb = 0.510000 . 0.490000  -  Accuracy: 95.72%\n",
      "0.52\n",
      "0.48\n",
      "\n",
      "rf . xgb = 0.520000 . 0.480000  -  Accuracy: 95.68%\n",
      "0.53\n",
      "0.47\n",
      "\n",
      "rf . xgb = 0.530000 . 0.470000  -  Accuracy: 95.66%\n",
      "0.54\n",
      "0.45999999999999996\n",
      "\n",
      "rf . xgb = 0.540000 . 0.460000  -  Accuracy: 95.63%\n",
      "0.55\n",
      "0.44999999999999996\n",
      "\n",
      "rf . xgb = 0.550000 . 0.450000  -  Accuracy: 95.60%\n",
      "0.56\n",
      "0.43999999999999995\n",
      "\n",
      "rf . xgb = 0.560000 . 0.440000  -  Accuracy: 95.56%\n",
      "0.57\n",
      "0.43000000000000005\n",
      "\n",
      "rf . xgb = 0.570000 . 0.430000  -  Accuracy: 95.54%\n",
      "0.58\n",
      "0.42000000000000004\n",
      "\n",
      "rf . xgb = 0.580000 . 0.420000  -  Accuracy: 95.52%\n",
      "0.59\n",
      "0.41000000000000003\n",
      "\n",
      "rf . xgb = 0.590000 . 0.410000  -  Accuracy: 95.50%\n",
      "0.6\n",
      "0.4\n",
      "\n",
      "rf . xgb = 0.600000 . 0.400000  -  Accuracy: 95.47%\n",
      "0.61\n",
      "0.39\n",
      "\n",
      "rf . xgb = 0.610000 . 0.390000  -  Accuracy: 95.44%\n",
      "0.62\n",
      "0.38\n",
      "\n",
      "rf . xgb = 0.620000 . 0.380000  -  Accuracy: 95.43%\n",
      "0.63\n",
      "0.37\n",
      "\n",
      "rf . xgb = 0.630000 . 0.370000  -  Accuracy: 95.39%\n",
      "0.64\n",
      "0.36\n",
      "\n",
      "rf . xgb = 0.640000 . 0.360000  -  Accuracy: 95.37%\n",
      "0.65\n",
      "0.35\n",
      "\n",
      "rf . xgb = 0.650000 . 0.350000  -  Accuracy: 95.34%\n",
      "0.66\n",
      "0.33999999999999997\n",
      "\n",
      "rf . xgb = 0.660000 . 0.340000  -  Accuracy: 95.30%\n",
      "0.67\n",
      "0.32999999999999996\n",
      "\n",
      "rf . xgb = 0.670000 . 0.330000  -  Accuracy: 95.29%\n",
      "0.68\n",
      "0.31999999999999995\n",
      "\n",
      "rf . xgb = 0.680000 . 0.320000  -  Accuracy: 95.25%\n",
      "0.69\n",
      "0.31000000000000005\n",
      "\n",
      "rf . xgb = 0.690000 . 0.310000  -  Accuracy: 95.19%\n",
      "0.7\n",
      "0.30000000000000004\n",
      "\n",
      "rf . xgb = 0.700000 . 0.300000  -  Accuracy: 95.17%\n",
      "0.71\n",
      "0.29000000000000004\n",
      "\n",
      "rf . xgb = 0.710000 . 0.290000  -  Accuracy: 95.13%\n",
      "0.72\n",
      "0.28\n",
      "\n",
      "rf . xgb = 0.720000 . 0.280000  -  Accuracy: 95.10%\n",
      "0.73\n",
      "0.27\n",
      "\n",
      "rf . xgb = 0.730000 . 0.270000  -  Accuracy: 95.06%\n",
      "0.74\n",
      "0.26\n",
      "\n",
      "rf . xgb = 0.740000 . 0.260000  -  Accuracy: 95.03%\n",
      "0.75\n",
      "0.25\n",
      "\n",
      "rf . xgb = 0.750000 . 0.250000  -  Accuracy: 94.96%\n",
      "0.76\n",
      "0.24\n",
      "\n",
      "rf . xgb = 0.760000 . 0.240000  -  Accuracy: 94.91%\n",
      "0.77\n",
      "0.22999999999999998\n",
      "\n",
      "rf . xgb = 0.770000 . 0.230000  -  Accuracy: 94.87%\n",
      "0.78\n",
      "0.21999999999999997\n",
      "\n",
      "rf . xgb = 0.780000 . 0.220000  -  Accuracy: 94.85%\n",
      "0.79\n",
      "0.20999999999999996\n",
      "\n",
      "rf . xgb = 0.790000 . 0.210000  -  Accuracy: 94.80%\n",
      "0.8\n",
      "0.19999999999999996\n",
      "\n",
      "rf . xgb = 0.800000 . 0.200000  -  Accuracy: 94.77%\n",
      "0.81\n",
      "0.18999999999999995\n",
      "\n",
      "rf . xgb = 0.810000 . 0.190000  -  Accuracy: 94.74%\n",
      "0.82\n",
      "0.18000000000000005\n",
      "\n",
      "rf . xgb = 0.820000 . 0.180000  -  Accuracy: 94.70%\n",
      "0.83\n",
      "0.17000000000000004\n",
      "\n",
      "rf . xgb = 0.830000 . 0.170000  -  Accuracy: 94.64%\n",
      "0.84\n",
      "0.16000000000000003\n",
      "\n",
      "rf . xgb = 0.840000 . 0.160000  -  Accuracy: 94.58%\n",
      "0.85\n",
      "0.15000000000000002\n",
      "\n",
      "rf . xgb = 0.850000 . 0.150000  -  Accuracy: 94.54%\n",
      "0.86\n",
      "0.14\n",
      "\n",
      "rf . xgb = 0.860000 . 0.140000  -  Accuracy: 94.49%\n",
      "0.87\n",
      "0.13\n",
      "\n",
      "rf . xgb = 0.870000 . 0.130000  -  Accuracy: 94.43%\n",
      "0.88\n",
      "0.12\n",
      "\n",
      "rf . xgb = 0.880000 . 0.120000  -  Accuracy: 94.37%\n",
      "0.89\n",
      "0.10999999999999999\n",
      "\n",
      "rf . xgb = 0.890000 . 0.110000  -  Accuracy: 94.32%\n",
      "0.9\n",
      "0.09999999999999998\n",
      "\n",
      "rf . xgb = 0.900000 . 0.100000  -  Accuracy: 94.15%\n",
      "0.91\n",
      "0.08999999999999997\n",
      "\n",
      "rf . xgb = 0.910000 . 0.090000  -  Accuracy: 94.09%\n",
      "0.92\n",
      "0.07999999999999996\n",
      "\n",
      "rf . xgb = 0.920000 . 0.080000  -  Accuracy: 94.07%\n",
      "0.93\n",
      "0.06999999999999995\n",
      "\n",
      "rf . xgb = 0.930000 . 0.070000  -  Accuracy: 94.04%\n",
      "0.94\n",
      "0.06000000000000005\n",
      "\n",
      "rf . xgb = 0.940000 . 0.060000  -  Accuracy: 93.89%\n",
      "0.95\n",
      "0.050000000000000044\n",
      "\n",
      "rf . xgb = 0.950000 . 0.050000  -  Accuracy: 93.87%\n",
      "0.96\n",
      "0.040000000000000036\n",
      "\n",
      "rf . xgb = 0.960000 . 0.040000  -  Accuracy: 93.81%\n",
      "0.97\n",
      "0.030000000000000027\n",
      "\n",
      "rf . xgb = 0.970000 . 0.030000  -  Accuracy: 93.60%\n",
      "0.98\n",
      "0.020000000000000018\n",
      "\n",
      "rf . xgb = 0.980000 . 0.020000  -  Accuracy: 93.59%\n",
      "0.99\n",
      "0.010000000000000009\n",
      "\n",
      "rf . xgb = 0.990000 . 0.010000  -  Accuracy: 93.49%\n"
     ]
    }
   ],
   "source": [
    "def combine_findWeight(seed):           \n",
    "    #Acquire training sample\n",
    "    (x,y_test) = rf(seed, False)\n",
    "    rand_score = [b for a,b in x]\n",
    "    \n",
    "    xgb_score = xgb(seed, False)\n",
    "    xgb_score = [b for a,b in xgb_score]   \n",
    "\n",
    "    print(\"SEED ------------ %i\" % (seed))\n",
    "    for rf_weight in range(1,100):\n",
    "        rf_weight = float(rf_weight/100)\n",
    "        xgb_weight = 1-rf_weight\n",
    "        print(rf_weight)\n",
    "        print(xgb_weight)\n",
    "        predictions = []\n",
    "        for i in range(0,len(rand_score)):\n",
    "            val = rand_score[i]*rf_weight + xgb_score[i]*xgb_weight\n",
    "            predictions.append(val)\n",
    "        predictions = [int(round(value)) for value in predictions]\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        print(\"rf . xgb = %f . %f  -  Accuracy: %.2f%%\" % (rf_weight, xgb_weight, accuracy * 100.0))  \n",
    "        print()\n",
    "\n",
    "    \n",
    "#seed, TO_TEST, rand forest weighting, xgboost weighting\n",
    "combine_findWeight(1)\n",
    "#for i in range(0,20):\n",
    "    #combine_findWeight(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF - Seed: 1    -  Accuracy: 90.60%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8510252 , 0.1489748 ],\n",
       "       [0.8510252 , 0.1489748 ],\n",
       "       [0.8510252 , 0.1489748 ],\n",
       "       ...,\n",
       "       [0.67682674, 0.32317326],\n",
       "       [0.2146204 , 0.7853796 ],\n",
       "       [0.8510252 , 0.1489748 ]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xgb(31,False)\n",
    "\n",
    "#for x in range (1,10):\n",
    "#    xgb(x, False)\n",
    "\n",
    "\n",
    "rf(1, True)\n",
    "#xgb(1, False)\n",
    "\n",
    "#for x in range (1,10):\n",
    "#    rf(x, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF - Seed: 2    -  Accuracy: 93.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/schubydooo/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb - Seed: 2    -  Accuracy: 95.93%\n"
     ]
    }
   ],
   "source": [
    "rf(2, False)\n",
    "xgb(2, False)       #just all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF - Seed: 1    -  Accuracy: 94.46%\n",
      "xgb - Seed: 1    -  Accuracy: 96.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/schubydooo/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "rf(1, False)\n",
    "xgb(1, False)   #baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
