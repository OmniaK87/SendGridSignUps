{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for building an XGBoost model for the Sendgrid sign up dataset\n",
    "***\n",
    "**Jake Mitchell Scott Schubert**\n",
    "\n",
    "Initially using ______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from numpy import loadtxt\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import randint\n",
    "from datetime import datetime\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movingaverage (values, window):\n",
    "    weights = np.repeat(1.0, window)/window\n",
    "    forwardsma = np.convolve(values, weights, 'valid')\n",
    "    #perform a moving average backwards, then reverse it back\n",
    "    backwardsma = np.convolve(values[::-1], weights, 'valid')[::-1]\n",
    "    \n",
    "\n",
    "    dualDirectionMA = np.zeros(len(values))\n",
    "    dualDirectionMA[len(dualDirectionMA)-window+1:] = forwardsma[len(forwardsma)-window+1:]\n",
    "    dualDirectionMA[:window-1] = backwardsma[:window-1]\n",
    "    dualDirectionMA[window-1:len(dualDirectionMA)-window+1] = [(a+b)/2 for a,b in zip(forwardsma[:len(forwardsma)-window+1], backwardsma[window-1:])]\n",
    "    return dualDirectionMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>banned_ip</th>\n",
       "      <th>ip_count</th>\n",
       "      <th>is_authy_verified</th>\n",
       "      <th>banned_email</th>\n",
       "      <th>is_transactional</th>\n",
       "      <th>is_marketing</th>\n",
       "      <th>is_behavioral</th>\n",
       "      <th>is_oem</th>\n",
       "      <th>risk</th>\n",
       "      <th>geolocation_risk</th>\n",
       "      <th>name_risk</th>\n",
       "      <th>ip_risk</th>\n",
       "      <th>community_risk</th>\n",
       "      <th>fingerprint_risk</th>\n",
       "      <th>email_risk</th>\n",
       "      <th>activity_risk</th>\n",
       "      <th>ip_cluster</th>\n",
       "      <th>email_cluster</th>\n",
       "      <th>mfa_required</th>\n",
       "      <th>mfa_completed</th>\n",
       "      <th>whitelabel_required</th>\n",
       "      <th>whitelabel_completed</th>\n",
       "      <th>payment_required</th>\n",
       "      <th>payment_completed</th>\n",
       "      <th>profile_completed</th>\n",
       "      <th>email_completed</th>\n",
       "      <th>employee_count_high</th>\n",
       "      <th>volume_high</th>\n",
       "      <th>developer</th>\n",
       "      <th>ceo</th>\n",
       "      <th>other</th>\n",
       "      <th>marketing</th>\n",
       "      <th>technical_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-155</td>\n",
       "      <td>-119</td>\n",
       "      <td>-10</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>2500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-25</td>\n",
       "      <td>-37</td>\n",
       "      <td>-10</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-44</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>100000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-72</td>\n",
       "      <td>-14</td>\n",
       "      <td>0</td>\n",
       "      <td>-40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id  banned_ip  ip_count  is_authy_verified  banned_email  \\\n",
       "0      0   0          6         8                  0             1   \n",
       "1      1   1          5         5                  0             1   \n",
       "2      2   2          0         1                  0             0   \n",
       "3      3   3          4         4                  0             2   \n",
       "4      4   4          0         1                  0             0   \n",
       "\n",
       "   is_transactional  is_marketing  is_behavioral  is_oem  risk  \\\n",
       "0                 0             0              0       0  -100   \n",
       "1                 1             0              0       0   -90   \n",
       "2                 1             0              0       0   -44   \n",
       "3                 0             1              0       0   -72   \n",
       "4                 1             0              0       0   -34   \n",
       "\n",
       "   geolocation_risk  name_risk  ip_risk  community_risk  fingerprint_risk  \\\n",
       "0                 0          0     -155            -119               -10   \n",
       "1                 0          0      -25             -37               -10   \n",
       "2               -16          0      -10               0                 0   \n",
       "3               -14          0      -40               0                 0   \n",
       "4               -16          0        0               0                 0   \n",
       "\n",
       "   email_risk  activity_risk  ip_cluster  email_cluster  mfa_required  \\\n",
       "0          -8              0       False          False           1.0   \n",
       "1          -8              0       False          False           0.0   \n",
       "2          -8              0       False          False           0.0   \n",
       "3          -8              0       False          False           1.0   \n",
       "4          -8              0       False          False           0.0   \n",
       "\n",
       "   mfa_completed  whitelabel_required  whitelabel_completed  payment_required  \\\n",
       "0            0.0                  1.0                   0.0               0.0   \n",
       "1            0.0                  0.0                   0.0               0.0   \n",
       "2            0.0                  0.0                   0.0               0.0   \n",
       "3            0.0                  1.0                   0.0               0.0   \n",
       "4            0.0                  0.0                   0.0               0.0   \n",
       "\n",
       "   payment_completed  profile_completed  email_completed  employee_count_high  \\\n",
       "0                0.0                1.0              0.0                  500   \n",
       "1                0.0                0.0              0.0                  500   \n",
       "2                0.0                0.0              0.0                  500   \n",
       "3                0.0                1.0              0.0                  500   \n",
       "4                0.0                0.0              0.0                  500   \n",
       "\n",
       "   volume_high  developer  ceo  other  marketing  technical_support  \n",
       "0      2500000          1    0      0          0                  0  \n",
       "1       100000          1    0      0          0                  0  \n",
       "2       100000          0    1      0          0                  0  \n",
       "3       100000          1    0      0          0                  0  \n",
       "4       100000          0    0      1          0                  0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = 'data/signup_train_data.csv'\n",
    "test_path = 'data/signup_test_data.csv'\n",
    "pd.options.display.max_columns = 2000\n",
    "\n",
    "\n",
    "# Load the data into a DataFrame \n",
    "df = pd.read_csv(train_path, low_memory=False)\n",
    "test_df = pd.read_csv(test_path, low_memory=False)\n",
    "\n",
    "# Split into X and Y\n",
    "dfLabels = df.pop(\"label\")\n",
    "#print (df.head())\n",
    "\n",
    "#Feature Engineering\n",
    "#for index, row in df.iterrows():\n",
    "#    df['time_of_day_int'] = introw['created_at'][11:13])*3600 + int(row['created_at'][14:16])*60 + int(row['created_at'][17:19])\n",
    "for dataframe in [df, test_df]:\n",
    "    # df['employee_count_low'] = 0\n",
    "    dataframe['employee_count_high'] = 0\n",
    "    # dataframe.loc[df['employee_count']  == '1 - 500', 'employee_count_low'] = 1\n",
    "    dataframe.loc[df['employee_count']  == '1 - 500', 'employee_count_high'] = 500\n",
    "    # dataframe.loc[df['employee_count']  == '501 - 1,000', 'employee_count_low'] = 501\n",
    "    dataframe.loc[df['employee_count']  == '501 - 1,000', 'employee_count_high'] = 1000\n",
    "    # dataframe.loc[df['employee_count']  == '1,001 - 5,000', 'employee_count_low'] = 1001\n",
    "    dataframe.loc[df['employee_count']  == '1,001 - 5,000', 'employee_count_high'] = 5000\n",
    "    # dataframe.loc[df['employee_count']  == '5,000+', 'employee_count_low'] = 5001\n",
    "    dataframe.loc[df['employee_count']  == '5,000+', 'employee_count_high'] = 10000\n",
    "    dataframe['volume_high'] = 0\n",
    "    dataframe.loc[df['volume']  == '1 - 100,000', 'volume_high'] = 100000\n",
    "    dataframe.loc[dataframe['volume']  == '100,001 - 2,500,000', 'volume_high'] = 2500000\n",
    "    dataframe.loc[dataframe['volume']  == '2,500,001 - 10,000,000', 'volume_high'] = 10000000\n",
    "    dataframe.loc[dataframe['volume']  == '10,000,000+', 'volume_high'] = 20000000\n",
    "    dataframe.loc[dataframe['volume']  == '0 to 40k', 'volume_high'] = 40000\n",
    "    dataframe.loc[dataframe['volume']  == '40k to 100k', 'volume_high'] = 100000\n",
    "    dataframe['developer'] = 0\n",
    "    dataframe.loc[dataframe['user_persona']  == 'Developer', 'developer'] = 1\n",
    "    dataframe['ceo'] = 0\n",
    "    dataframe.loc[dataframe['user_persona']  == 'CEO', 'ceo'] = 1\n",
    "    dataframe['other'] = 0\n",
    "    dataframe.loc[dataframe['user_persona']  == 'Other', 'other'] = 1\n",
    "    dataframe['marketing'] = 0\n",
    "    dataframe.loc[dataframe['user_persona']  == 'Marketing', 'marketing'] = 1\n",
    "    dataframe['technical_support'] = 0\n",
    "    dataframe.loc[dataframe['user_persona']  == 'Technical Support', 'technical_support'] = 1\n",
    "\n",
    "\n",
    "\n",
    "#Temporarily parse non numerical data\n",
    "#,'user_persona'\n",
    "frames_to_remove = ['zip', 'city', 'website', 'state', 'country', 'registration_ip', 'company','multifactor_country_code','created_at','lead_source','marketing_channel','initial_package','geolocation_notes','name_notes','ip_notes','community_notes','email_notes','activity_notes','fingerprint_notes','employee_count','volume','user_persona']\n",
    "df = df.drop(frames_to_remove, axis=1)\n",
    "test_df = test_df.drop(frames_to_remove, axis=1)\n",
    "\n",
    "df.fillna(value=0, inplace=True)\n",
    "test_df.fillna(value=0, inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "test_df.reset_index(inplace=True)\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100  -90  -44  -72  -34  -19   -9  -18  -54  -52  -16  -51  -41  -28\n",
      "  -37  -46  -33  -29  -15  -38  -56  -17  -66  -31  -25  -61  -57  -32\n",
      "  -98  -77  -47  -94  -62  -23  -21  -24   -8  -42  -91  -14  -60  -35\n",
      "  -71  -45  -20  -96  -81  -53  -43  -65  -93  -49  -64  -36  -10  -99\n",
      "  -67  -95  -85  -80  -75  -74  -73  -68  -70  -79  -12  -69  -55  -88\n",
      "  -39  -59  -11  -89  -48  -58  -63  -30  -82  -50  -27  -78  -76  -87\n",
      "  -84  -22  -92  -86  -83  -97  -40  -26  100   95   -7  -13    1   78\n",
      "   80   94   85   75    0   -3   74   55   -4   -5   -6   -1   -2   64\n",
      "   72   88   92   81   86   84   61   98   62   70   65   99   48   69\n",
      "   59   56   96   68   44   83]\n"
     ]
    }
   ],
   "source": [
    "print(df['risk'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValidateClassifier(classifierFunction, standardize=False, **kwargs):\n",
    "    '''The classifierFunction should be a function that takes (x_train, y_train, X_valid, Y_valid, **kwargs)\n",
    "       and returns (train_accuracy, valid_accuracy) from that classifier'''\n",
    "    splits = 2\n",
    "    accuracys = np.zeros((2,splits), dtype=float)\n",
    "    \n",
    "    print(\"Running Cross Validation on {0} with parameters {1}\".format(classifierFunction.__name__, kwargs))\n",
    "    skf = StratifiedKFold(n_splits=splits, shuffle=True)\n",
    "    for i, (train_indexes, valid_indexes) in enumerate(skf.split(df, dfLabels)):\n",
    "        fold_X_train, fold_y_train = df.iloc[train_indexes], dfLabels.iloc[train_indexes]  \n",
    "        fold_X_valid, fold_y_valid = df.iloc[valid_indexes], dfLabels.iloc[valid_indexes]    \n",
    "\n",
    "        (accuracys[0][i], accuracys[1][i]) = classifierFunction(fold_X_train, fold_y_train, fold_X_valid, fold_y_valid, kwargs)\n",
    "        print(\"    Fold {1}: Train Accuracy: {2:.4f} Valid Accuracy: {3:.4f}\".format(kwargs, i, accuracys[0][i] , accuracys[1][i]))\n",
    "    meanAccuracy = (np.mean(accuracys[0]), np.mean(accuracys[1]))\n",
    "    print(\"{0} with parameters {1} === Train Accuracy: {2:.4f} Mean Valid Accuracy: {3:.4f}\".format(classifierFunction.__name__, kwargs, meanAccuracy[0], meanAccuracy[1]))\n",
    "    print(\"\\n\\n\")\n",
    "    return meanAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FinalAccuracyClassifier(classifierModel, **kwargs):\n",
    "    '''The classifierFunction should be a function that takes (x_train, y_train, **kwargs)\n",
    "       trains a model and returns final accuracy from that classifier'''\n",
    "    model = classifierModel(df,dfLabels,kwargs)\n",
    "    y_pred = model.predict(test_df)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "\n",
    "    d = {'id':test_df['id'], 'label':predictions}\n",
    "    preds = pd.DataFrame(data=d)\n",
    "\n",
    "    preds.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSVMClassifier(X_train, y_train, X_valid, y_valid, hyperparameters):\n",
    "    '''Takes (x_train, y_train, X_valid, Y_valid, {})\n",
    "       returns (train_accuracy, valid_accuracy)\n",
    "       \n",
    "       We want to use the dual false (run the primal problem) due to the size of the dataset'''\n",
    "    lsvm = LinearSVC(dual=hyperparameters[\"dual\"])\n",
    "    lsvm.fit(X_train,y_train)\n",
    "    return (lsvm.score(X_train, y_train), lsvm.score(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CrossValidateClassifier(LSVMClassifier, dual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaClassifier(X_train, y_train, X_valid, y_valid, hyperparameters):\n",
    "    '''Takes (x_train, y_train, X_valid, Y_valid, {})\n",
    "       returns (train_accuracy, valid_accuracy)'''\n",
    "    ada = AdaBoostClassifier(base_estimator=hyperparameters['base_estimator'], n_estimators=hyperparameters['n_estimators'], learning_rate=hyperparameters['learning_rate'])\n",
    "    ada.fit(X_train,y_train)\n",
    "    return (ada.score(X_train, y_train), ada.score(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaPredClassifier(X_train, y_train, hyperparameters):\n",
    "    ada = AdaBoostClassifier(base_estimator=hyperparameters['base_estimator'], n_estimators=hyperparameters['n_estimators'], learning_rate=hyperparameters['learning_rate'])\n",
    "    ada.fit(X_train,y_train)\n",
    "    return ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f09c22b11b49158a665afa01ef906e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FloatProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FloatProgress(value=0.0, max=60.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = FloatProgress(min=0, max=3*5*4)\n",
    "display(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'n_estimators': 50, 'learning_rate': 0.9}\n",
      "    Fold 0: Train Accuracy: 0.9401 Valid Accuracy: 0.9396\n",
      "    Fold 1: Train Accuracy: 0.9407 Valid Accuracy: 0.9409\n",
      "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'n_estimators': 50, 'learning_rate': 0.9} === Train Accuracy: 0.9404 Mean Valid Accuracy: 0.9402\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Apparently there is a trade off between n and learning rate, also taking a look at depth because of how important it is'''\n",
    "adaAccuracyList = np.zeros((5,1), dtype=float)\n",
    "i = 0\n",
    "for n in [50]:\n",
    "    for learning_rate in [0.9]:\n",
    "        for depth in [1]:\n",
    "            adaAccuracyList[0][i] = n\n",
    "            adaAccuracyList[1][i] = learning_rate\n",
    "            adaAccuracyList[2][i] = depth\n",
    "            (adaAccuracyList[3][i], adaAccuracyList[4][i]) = CrossValidateClassifier(AdaClassifier, base_estimator=DecisionTreeClassifier(max_depth=depth), n_estimators=n, learning_rate=learning_rate)\n",
    "            f.value += 1\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Current best hyper parameters are 150 estimators, 0.9 learning rate, depth of 4.  With this kind of stuff we can just up the depth and estimators and keep getting little benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9746470774962117\n",
      "[0 1 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=4), n_estimators=150, learning_rate=0.9)\n",
    "ada.fit(df, dfLabels)\n",
    "print(ada.score(df, dfLabels))\n",
    "yhat = ada.predict(test_df)\n",
    "print(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [round(value) for value in yhat]\n",
    "\n",
    "d = {'id':test_df['id'], 'label':predictions}\n",
    "preds = pd.DataFrame(data=d)\n",
    "\n",
    "preds.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_basic(seed_in, TO_TEST, eta=0.1, depth=3, n_estimators=100, split=0.5):\n",
    "    # split data into train and test sets\n",
    "    seed = seed_in\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df, dfLabels, test_size=1-split, random_state=seed)\n",
    "\n",
    "    # fit model no training data\n",
    "    model = XGBClassifier(learning_rate=eta, max_depth=depth, n_estimators=n_estimators)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # make predictions for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Seed: %i Eta: %f Depth: %i Estimators: %i  -  Accuracy: %.3f%%\" % (seed, eta, depth, n_estimators, accuracy * 100.0))\n",
    "    \n",
    "    if TO_TEST:\n",
    "        #make predictions for train data\n",
    "        y_pred = model.predict(test_df)\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "\n",
    "        d = {'id':test_df['id'], 'label':predictions}\n",
    "        preds = pd.DataFrame(data=d)\n",
    "\n",
    "        preds.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for split in [0.5,0.6,0.7,0.75,0.8,0.85,0.9,0.95]:\n",
    "#     xgb_basic(31,False, depth=9, eta=0.15, n_estimators=n_estimators, split=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_basic(1, False, depth=9, eta=0.15, n_estimators=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_basic(1, True, depth=9, eta=0.15, n_estimators=120, split=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 0.9}\n",
    "    Fold 0: Train Accuracy: 0.9380 Valid Accuracy: 0.9389\n",
    "    Fold 1: Train Accuracy: 0.9390 Valid Accuracy: 0.9386\n",
    "    Fold 2: Train Accuracy: 0.9418 Valid Accuracy: 0.9410\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 0.9} === Train Accuracy: 0.9396 Mean Valid Accuracy: 0.9395\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 0.9}\n",
    "    Fold 0: Train Accuracy: 0.9567 Valid Accuracy: 0.9572\n",
    "    Fold 1: Train Accuracy: 0.9564 Valid Accuracy: 0.9561\n",
    "    Fold 2: Train Accuracy: 0.9570 Valid Accuracy: 0.9559\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 0.9} === Train Accuracy: 0.9567 Mean Valid Accuracy: 0.9564\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 0.9}\n",
    "    Fold 0: Train Accuracy: 0.9628 Valid Accuracy: 0.9619\n",
    "    Fold 1: Train Accuracy: 0.9629 Valid Accuracy: 0.9626\n",
    "    Fold 2: Train Accuracy: 0.9634 Valid Accuracy: 0.9627\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 0.9} === Train Accuracy: 0.9630 Mean Valid Accuracy: 0.9624\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 0.9}\n",
    "    Fold 0: Train Accuracy: 0.9676 Valid Accuracy: 0.9658\n",
    "    Fold 1: Train Accuracy: 0.9677 Valid Accuracy: 0.9670\n",
    "    Fold 2: Train Accuracy: 0.9663 Valid Accuracy: 0.9643\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 0.9} === Train Accuracy: 0.9672 Mean Valid Accuracy: 0.9657\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 0.95}\n",
    "    Fold 0: Train Accuracy: 0.9361 Valid Accuracy: 0.9365\n",
    "    Fold 1: Train Accuracy: 0.9391 Valid Accuracy: 0.9387\n",
    "    Fold 2: Train Accuracy: 0.9402 Valid Accuracy: 0.9398\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 0.95} === Train Accuracy: 0.9384 Mean Valid Accuracy: 0.9384\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 0.95}\n",
    "    Fold 0: Train Accuracy: 0.9568 Valid Accuracy: 0.9561\n",
    "    Fold 1: Train Accuracy: 0.9566 Valid Accuracy: 0.9571\n",
    "    Fold 2: Train Accuracy: 0.9557 Valid Accuracy: 0.9550\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 0.95} === Train Accuracy: 0.9564 Mean Valid Accuracy: 0.9561\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 0.95}\n",
    "    Fold 0: Train Accuracy: 0.9631 Valid Accuracy: 0.9635\n",
    "    Fold 1: Train Accuracy: 0.9635 Valid Accuracy: 0.9611\n",
    "    Fold 2: Train Accuracy: 0.9627 Valid Accuracy: 0.9628\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 0.95} === Train Accuracy: 0.9631 Mean Valid Accuracy: 0.9625\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 0.95}\n",
    "    Fold 0: Train Accuracy: 0.9685 Valid Accuracy: 0.9671\n",
    "    Fold 1: Train Accuracy: 0.9680 Valid Accuracy: 0.9657\n",
    "    Fold 2: Train Accuracy: 0.9670 Valid Accuracy: 0.9665\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 0.95} === Train Accuracy: 0.9678 Mean Valid Accuracy: 0.9664\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1}\n",
    "    Fold 0: Train Accuracy: 0.9415 Valid Accuracy: 0.9410\n",
    "    Fold 1: Train Accuracy: 0.9367 Valid Accuracy: 0.9359\n",
    "    Fold 2: Train Accuracy: 0.9380 Valid Accuracy: 0.9391\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1} === Train Accuracy: 0.9387 Mean Valid Accuracy: 0.9386\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1}\n",
    "    Fold 0: Train Accuracy: 0.9561 Valid Accuracy: 0.9545\n",
    "    Fold 1: Train Accuracy: 0.9544 Valid Accuracy: 0.9551\n",
    "    Fold 2: Train Accuracy: 0.9572 Valid Accuracy: 0.9573\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1} === Train Accuracy: 0.9559 Mean Valid Accuracy: 0.9556\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1}\n",
    "    Fold 0: Train Accuracy: 0.9650 Valid Accuracy: 0.9644\n",
    "    Fold 1: Train Accuracy: 0.9639 Valid Accuracy: 0.9635\n",
    "    Fold 2: Train Accuracy: 0.9649 Valid Accuracy: 0.9645\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1} === Train Accuracy: 0.9646 Mean Valid Accuracy: 0.9641\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1}\n",
    "    Fold 0: Train Accuracy: 0.9681 Valid Accuracy: 0.9668\n",
    "    Fold 1: Train Accuracy: 0.9687 Valid Accuracy: 0.9671\n",
    "    Fold 2: Train Accuracy: 0.9678 Valid Accuracy: 0.9662\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1} === Train Accuracy: 0.9682 Mean Valid Accuracy: 0.9667\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1.05}\n",
    "    Fold 0: Train Accuracy: 0.9374 Valid Accuracy: 0.9369\n",
    "    Fold 1: Train Accuracy: 0.9398 Valid Accuracy: 0.9417\n",
    "    Fold 2: Train Accuracy: 0.9387 Valid Accuracy: 0.9378\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1.05} === Train Accuracy: 0.9386 Mean Valid Accuracy: 0.9388\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1.05}\n",
    "    Fold 0: Train Accuracy: 0.9567 Valid Accuracy: 0.9567\n",
    "    Fold 1: Train Accuracy: 0.9556 Valid Accuracy: 0.9570\n",
    "    Fold 2: Train Accuracy: 0.9562 Valid Accuracy: 0.9545\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1.05} === Train Accuracy: 0.9561 Mean Valid Accuracy: 0.9561\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1.05}\n",
    "    Fold 0: Train Accuracy: 0.9626 Valid Accuracy: 0.9624\n",
    "    Fold 1: Train Accuracy: 0.9621 Valid Accuracy: 0.9613\n",
    "    Fold 2: Train Accuracy: 0.9629 Valid Accuracy: 0.9624\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1.05} === Train Accuracy: 0.9625 Mean Valid Accuracy: 0.9620\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1.05}\n",
    "    Fold 0: Train Accuracy: 0.9677 Valid Accuracy: 0.9666\n",
    "    Fold 1: Train Accuracy: 0.9671 Valid Accuracy: 0.9652\n",
    "    Fold 2: Train Accuracy: 0.9684 Valid Accuracy: 0.9664\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1.05} === Train Accuracy: 0.9677 Mean Valid Accuracy: 0.9661\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1.1}\n",
    "    Fold 0: Train Accuracy: 0.9397 Valid Accuracy: 0.9394\n",
    "    Fold 1: Train Accuracy: 0.9397 Valid Accuracy: 0.9387\n",
    "    Fold 2: Train Accuracy: 0.9398 Valid Accuracy: 0.9417\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1.1} === Train Accuracy: 0.9398 Mean Valid Accuracy: 0.9399\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1.1}\n",
    "    Fold 0: Train Accuracy: 0.9545 Valid Accuracy: 0.9539\n",
    "    Fold 1: Train Accuracy: 0.9549 Valid Accuracy: 0.9551\n",
    "    Fold 2: Train Accuracy: 0.9560 Valid Accuracy: 0.9552\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1.1} === Train Accuracy: 0.9551 Mean Valid Accuracy: 0.9547\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1.1}\n",
    "    Fold 0: Train Accuracy: 0.9635 Valid Accuracy: 0.9616\n",
    "    Fold 1: Train Accuracy: 0.9623 Valid Accuracy: 0.9609\n",
    "    Fold 2: Train Accuracy: 0.9640 Valid Accuracy: 0.9643\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1.1} === Train Accuracy: 0.9633 Mean Valid Accuracy: 0.9623\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1.1}\n",
    "    Fold 0: Train Accuracy: 0.9677 Valid Accuracy: 0.9663\n",
    "    Fold 1: Train Accuracy: 0.9679 Valid Accuracy: 0.9660\n",
    "    Fold 2: Train Accuracy: 0.9674 Valid Accuracy: 0.9660\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 30, 'learning_rate': 1.1} === Train Accuracy: 0.9677 Mean Valid Accuracy: 0.9661\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 0.9}\n",
    "    Fold 0: Train Accuracy: 0.9400 Valid Accuracy: 0.9410\n",
    "    Fold 1: Train Accuracy: 0.9400 Valid Accuracy: 0.9377\n",
    "    Fold 2: Train Accuracy: 0.9403 Valid Accuracy: 0.9412\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 0.9} === Train Accuracy: 0.9401 Mean Valid Accuracy: 0.9400\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 0.9}\n",
    "    Fold 0: Train Accuracy: 0.9597 Valid Accuracy: 0.9603\n",
    "    Fold 1: Train Accuracy: 0.9603 Valid Accuracy: 0.9594\n",
    "    Fold 2: Train Accuracy: 0.9593 Valid Accuracy: 0.9586\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 0.9} === Train Accuracy: 0.9598 Mean Valid Accuracy: 0.9594\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 0.9}\n",
    "    Fold 0: Train Accuracy: 0.9653 Valid Accuracy: 0.9638\n",
    "    Fold 1: Train Accuracy: 0.9660 Valid Accuracy: 0.9652\n",
    "    Fold 2: Train Accuracy: 0.9653 Valid Accuracy: 0.9645\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 0.9} === Train Accuracy: 0.9655 Mean Valid Accuracy: 0.9645\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 0.9}\n",
    "    Fold 0: Train Accuracy: 0.9706 Valid Accuracy: 0.9679\n",
    "    Fold 1: Train Accuracy: 0.9700 Valid Accuracy: 0.9669\n",
    "    Fold 2: Train Accuracy: 0.9705 Valid Accuracy: 0.9680\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 0.9} === Train Accuracy: 0.9703 Mean Valid Accuracy: 0.9676\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 0.95}\n",
    "    Fold 0: Train Accuracy: 0.9403 Valid Accuracy: 0.9404\n",
    "    Fold 1: Train Accuracy: 0.9410 Valid Accuracy: 0.9415\n",
    "    Fold 2: Train Accuracy: 0.9420 Valid Accuracy: 0.9409\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 0.95} === Train Accuracy: 0.9411 Mean Valid Accuracy: 0.9409\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 0.95}\n",
    "    Fold 0: Train Accuracy: 0.9578 Valid Accuracy: 0.9575\n",
    "    Fold 1: Train Accuracy: 0.9601 Valid Accuracy: 0.9603\n",
    "    Fold 2: Train Accuracy: 0.9596 Valid Accuracy: 0.9596\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 0.95} === Train Accuracy: 0.9592 Mean Valid Accuracy: 0.9591\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 0.95}\n",
    "    Fold 0: Train Accuracy: 0.9649 Valid Accuracy: 0.9635\n",
    "    Fold 1: Train Accuracy: 0.9650 Valid Accuracy: 0.9633\n",
    "    Fold 2: Train Accuracy: 0.9644 Valid Accuracy: 0.9647\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 0.95} === Train Accuracy: 0.9647 Mean Valid Accuracy: 0.9638\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 0.95}\n",
    "    Fold 0: Train Accuracy: 0.9702 Valid Accuracy: 0.9681\n",
    "    Fold 1: Train Accuracy: 0.9702 Valid Accuracy: 0.9682\n",
    "    Fold 2: Train Accuracy: 0.9702 Valid Accuracy: 0.9670\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 0.95} === Train Accuracy: 0.9702 Mean Valid Accuracy: 0.9678\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1}\n",
    "    Fold 0: Train Accuracy: 0.9411 Valid Accuracy: 0.9407\n",
    "    Fold 1: Train Accuracy: 0.9403 Valid Accuracy: 0.9410\n",
    "    Fold 2: Train Accuracy: 0.9414 Valid Accuracy: 0.9410\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1} === Train Accuracy: 0.9409 Mean Valid Accuracy: 0.9409\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1}\n",
    "    Fold 0: Train Accuracy: 0.9607 Valid Accuracy: 0.9599\n",
    "    Fold 1: Train Accuracy: 0.9596 Valid Accuracy: 0.9586\n",
    "    Fold 2: Train Accuracy: 0.9590 Valid Accuracy: 0.9598\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1} === Train Accuracy: 0.9597 Mean Valid Accuracy: 0.9595\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1}\n",
    "    Fold 0: Train Accuracy: 0.9649 Valid Accuracy: 0.9646\n",
    "    Fold 1: Train Accuracy: 0.9657 Valid Accuracy: 0.9640\n",
    "    Fold 2: Train Accuracy: 0.9661 Valid Accuracy: 0.9653\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1} === Train Accuracy: 0.9655 Mean Valid Accuracy: 0.9646\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1}\n",
    "    Fold 0: Train Accuracy: 0.9701 Valid Accuracy: 0.9676\n",
    "    Fold 1: Train Accuracy: 0.9700 Valid Accuracy: 0.9671\n",
    "    Fold 2: Train Accuracy: 0.9700 Valid Accuracy: 0.9674\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1} === Train Accuracy: 0.9700 Mean Valid Accuracy: 0.9673\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1.05}\n",
    "    Fold 0: Train Accuracy: 0.9405 Valid Accuracy: 0.9412\n",
    "    Fold 1: Train Accuracy: 0.9417 Valid Accuracy: 0.9414\n",
    "    Fold 2: Train Accuracy: 0.9424 Valid Accuracy: 0.9420\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1.05} === Train Accuracy: 0.9415 Mean Valid Accuracy: 0.9415\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1.05}\n",
    "    Fold 0: Train Accuracy: 0.9604 Valid Accuracy: 0.9590\n",
    "    Fold 1: Train Accuracy: 0.9588 Valid Accuracy: 0.9595\n",
    "    Fold 2: Train Accuracy: 0.9599 Valid Accuracy: 0.9589\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1.05} === Train Accuracy: 0.9597 Mean Valid Accuracy: 0.9591\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1.05}\n",
    "    Fold 0: Train Accuracy: 0.9653 Valid Accuracy: 0.9638\n",
    "    Fold 1: Train Accuracy: 0.9663 Valid Accuracy: 0.9652\n",
    "    Fold 2: Train Accuracy: 0.9646 Valid Accuracy: 0.9647\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1.05} === Train Accuracy: 0.9654 Mean Valid Accuracy: 0.9646\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1.05}\n",
    "    Fold 0: Train Accuracy: 0.9705 Valid Accuracy: 0.9673\n",
    "    Fold 1: Train Accuracy: 0.9703 Valid Accuracy: 0.9669\n",
    "    Fold 2: Train Accuracy: 0.9691 Valid Accuracy: 0.9665\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1.05} === Train Accuracy: 0.9699 Mean Valid Accuracy: 0.9669\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1.1}\n",
    "    Fold 0: Train Accuracy: 0.9418 Valid Accuracy: 0.9427\n",
    "    Fold 1: Train Accuracy: 0.9429 Valid Accuracy: 0.9409\n",
    "    Fold 2: Train Accuracy: 0.9428 Valid Accuracy: 0.9439\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1.1} === Train Accuracy: 0.9425 Mean Valid Accuracy: 0.9425\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1.1}\n",
    "    Fold 0: Train Accuracy: 0.9603 Valid Accuracy: 0.9603\n",
    "    Fold 1: Train Accuracy: 0.9592 Valid Accuracy: 0.9591\n",
    "    Fold 2: Train Accuracy: 0.9571 Valid Accuracy: 0.9573\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1.1} === Train Accuracy: 0.9589 Mean Valid Accuracy: 0.9589\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1.1}\n",
    "    Fold 0: Train Accuracy: 0.9657 Valid Accuracy: 0.9647\n",
    "    Fold 1: Train Accuracy: 0.9661 Valid Accuracy: 0.9652\n",
    "    Fold 2: Train Accuracy: 0.9657 Valid Accuracy: 0.9642\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1.1} === Train Accuracy: 0.9658 Mean Valid Accuracy: 0.9647\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1.1}\n",
    "    Fold 0: Train Accuracy: 0.9692 Valid Accuracy: 0.9662\n",
    "    Fold 1: Train Accuracy: 0.9706 Valid Accuracy: 0.9670\n",
    "    Fold 2: Train Accuracy: 0.9698 Valid Accuracy: 0.9679\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 50, 'learning_rate': 1.1} === Train Accuracy: 0.9698 Mean Valid Accuracy: 0.9670\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 0.9}\n",
    "    Fold 0: Train Accuracy: 0.9424 Valid Accuracy: 0.9431\n",
    "    Fold 1: Train Accuracy: 0.9421 Valid Accuracy: 0.9422\n",
    "    Fold 2: Train Accuracy: 0.9421 Valid Accuracy: 0.9409\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 0.9} === Train Accuracy: 0.9422 Mean Valid Accuracy: 0.9421\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 0.9}\n",
    "    Fold 0: Train Accuracy: 0.9627 Valid Accuracy: 0.9630\n",
    "    Fold 1: Train Accuracy: 0.9630 Valid Accuracy: 0.9617\n",
    "    Fold 2: Train Accuracy: 0.9631 Valid Accuracy: 0.9622\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 0.9} === Train Accuracy: 0.9629 Mean Valid Accuracy: 0.9623\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 0.9}\n",
    "    Fold 0: Train Accuracy: 0.9693 Valid Accuracy: 0.9670\n",
    "    Fold 1: Train Accuracy: 0.9691 Valid Accuracy: 0.9673\n",
    "    Fold 2: Train Accuracy: 0.9694 Valid Accuracy: 0.9672\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 0.9} === Train Accuracy: 0.9693 Mean Valid Accuracy: 0.9672\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 0.9}\n",
    "    Fold 0: Train Accuracy: 0.9727 Valid Accuracy: 0.9689\n",
    "    Fold 1: Train Accuracy: 0.9736 Valid Accuracy: 0.9682\n",
    "    Fold 2: Train Accuracy: 0.9740 Valid Accuracy: 0.9690\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 0.9} === Train Accuracy: 0.9734 Mean Valid Accuracy: 0.9687\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 0.95}\n",
    "    Fold 0: Train Accuracy: 0.9427 Valid Accuracy: 0.9425\n",
    "    Fold 1: Train Accuracy: 0.9427 Valid Accuracy: 0.9426\n",
    "    Fold 2: Train Accuracy: 0.9420 Valid Accuracy: 0.9421\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 0.95} === Train Accuracy: 0.9425 Mean Valid Accuracy: 0.9424\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 0.95}\n",
    "    Fold 0: Train Accuracy: 0.9631 Valid Accuracy: 0.9604\n",
    "    Fold 1: Train Accuracy: 0.9617 Valid Accuracy: 0.9621\n",
    "    Fold 2: Train Accuracy: 0.9622 Valid Accuracy: 0.9623\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 0.95} === Train Accuracy: 0.9623 Mean Valid Accuracy: 0.9616\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 0.95}\n",
    "    Fold 0: Train Accuracy: 0.9685 Valid Accuracy: 0.9661\n",
    "    Fold 1: Train Accuracy: 0.9693 Valid Accuracy: 0.9677\n",
    "    Fold 2: Train Accuracy: 0.9691 Valid Accuracy: 0.9667\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 0.95} === Train Accuracy: 0.9690 Mean Valid Accuracy: 0.9668\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 0.95}\n",
    "    Fold 0: Train Accuracy: 0.9736 Valid Accuracy: 0.9680\n",
    "    Fold 1: Train Accuracy: 0.9728 Valid Accuracy: 0.9682\n",
    "    Fold 2: Train Accuracy: 0.9724 Valid Accuracy: 0.9685\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 0.95} === Train Accuracy: 0.9729 Mean Valid Accuracy: 0.9682\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1}\n",
    "    Fold 0: Train Accuracy: 0.9426 Valid Accuracy: 0.9432\n",
    "    Fold 1: Train Accuracy: 0.9422 Valid Accuracy: 0.9423\n",
    "    Fold 2: Train Accuracy: 0.9441 Valid Accuracy: 0.9425\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1} === Train Accuracy: 0.9430 Mean Valid Accuracy: 0.9426\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1}\n",
    "    Fold 0: Train Accuracy: 0.9636 Valid Accuracy: 0.9624\n",
    "    Fold 1: Train Accuracy: 0.9636 Valid Accuracy: 0.9633\n",
    "    Fold 2: Train Accuracy: 0.9634 Valid Accuracy: 0.9626\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1} === Train Accuracy: 0.9635 Mean Valid Accuracy: 0.9628\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1}\n",
    "    Fold 0: Train Accuracy: 0.9694 Valid Accuracy: 0.9680\n",
    "    Fold 1: Train Accuracy: 0.9690 Valid Accuracy: 0.9669\n",
    "    Fold 2: Train Accuracy: 0.9690 Valid Accuracy: 0.9671\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1} === Train Accuracy: 0.9691 Mean Valid Accuracy: 0.9673\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1}\n",
    "    Fold 0: Train Accuracy: 0.9734 Valid Accuracy: 0.9687\n",
    "    Fold 1: Train Accuracy: 0.9734 Valid Accuracy: 0.9683\n",
    "    Fold 2: Train Accuracy: 0.9729 Valid Accuracy: 0.9677\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1} === Train Accuracy: 0.9732 Mean Valid Accuracy: 0.9682\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1.05}\n",
    "    Fold 0: Train Accuracy: 0.9424 Valid Accuracy: 0.9435\n",
    "    Fold 1: Train Accuracy: 0.9439 Valid Accuracy: 0.9422\n",
    "    Fold 2: Train Accuracy: 0.9425 Valid Accuracy: 0.9432\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1.05} === Train Accuracy: 0.9429 Mean Valid Accuracy: 0.9430\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1.05}\n",
    "    Fold 0: Train Accuracy: 0.9625 Valid Accuracy: 0.9623\n",
    "    Fold 1: Train Accuracy: 0.9626 Valid Accuracy: 0.9616\n",
    "    Fold 2: Train Accuracy: 0.9624 Valid Accuracy: 0.9614\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1.05} === Train Accuracy: 0.9625 Mean Valid Accuracy: 0.9618\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1.05}\n",
    "    Fold 0: Train Accuracy: 0.9690 Valid Accuracy: 0.9673\n",
    "    Fold 1: Train Accuracy: 0.9688 Valid Accuracy: 0.9665\n",
    "    Fold 2: Train Accuracy: 0.9690 Valid Accuracy: 0.9672\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1.05} === Train Accuracy: 0.9690 Mean Valid Accuracy: 0.9670\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1.05}\n",
    "    Fold 0: Train Accuracy: 0.9732 Valid Accuracy: 0.9688\n",
    "    Fold 1: Train Accuracy: 0.9732 Valid Accuracy: 0.9689\n",
    "    Fold 2: Train Accuracy: 0.9732 Valid Accuracy: 0.9672\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1.05} === Train Accuracy: 0.9732 Mean Valid Accuracy: 0.9683\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1.1}\n",
    "    Fold 0: Train Accuracy: 0.9434 Valid Accuracy: 0.9434\n",
    "    Fold 1: Train Accuracy: 0.9431 Valid Accuracy: 0.9425\n",
    "    Fold 2: Train Accuracy: 0.9433 Valid Accuracy: 0.9439\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1.1} === Train Accuracy: 0.9433 Mean Valid Accuracy: 0.9432\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1.1}\n",
    "    Fold 0: Train Accuracy: 0.9627 Valid Accuracy: 0.9624\n",
    "    Fold 1: Train Accuracy: 0.9622 Valid Accuracy: 0.9635\n",
    "    Fold 2: Train Accuracy: 0.9633 Valid Accuracy: 0.9609\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1.1} === Train Accuracy: 0.9627 Mean Valid Accuracy: 0.9623\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1.1}\n",
    "    Fold 0: Train Accuracy: 0.9685 Valid Accuracy: 0.9664\n",
    "    Fold 1: Train Accuracy: 0.9688 Valid Accuracy: 0.9662\n",
    "    Fold 2: Train Accuracy: 0.9687 Valid Accuracy: 0.9671\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1.1} === Train Accuracy: 0.9686 Mean Valid Accuracy: 0.9666\n",
    "\n",
    "\n",
    "\n",
    "Running Cross Validation on AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1.1}\n",
    "    Fold 0: Train Accuracy: 0.9725 Valid Accuracy: 0.9683\n",
    "    Fold 1: Train Accuracy: 0.9735 Valid Accuracy: 0.9679\n",
    "    Fold 2: Train Accuracy: 0.9725 Valid Accuracy: 0.9660\n",
    "AdaClassifier with parameters {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'), 'n_estimators': 100, 'learning_rate': 1.1} === Train Accuracy: 0.9728 Mean Valid Accuracy: 0.9674"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
